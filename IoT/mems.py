# -*- coding: utf-8 -*-
"""mems.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16odI1LmpBqZWWyV1fRNl1g_anodARP5Y

#models
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier, VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from mlxtend.classifier import StackingClassifier
import matplotlib.pyplot as plt
from tabulate import tabulate

# Load your dataset (replace 'your_dataset.csv' with your actual dataset file)
# Assuming your dataset is in CSV format with columns 'x', 'y', 'z', and 'label'
dataset = pd.read_csv('/content/drive/MyDrive/mems_dataset.csv')

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import matplotlib.pyplot as pltF
from tabulate import tabulate

# Load dataset
dataset = pd.read_csv('/content/drive/MyDrive/mems_dataset.csv')

# Extract features and labels
X = dataset[['x', 'y', 'z']].values
y = dataset['label'].values

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# ------------------- SVM Model -------------------
svm_classifier = SVC(kernel='linear', probability=True, random_state=42)
svm_classifier.fit(X_train, y_train)
svm_pred = svm_classifier.predict(X_test)

# ------------------- Evaluation Function -------------------
def evaluate_and_report(y_true, y_pred, model_name):
    accuracy = accuracy_score(y_true, y_pred)
    report = classification_report(y_true, y_pred)
    conf_matrix = confusion_matrix(y_true, y_pred)

    # Print results
    print("\n\n==============================")
    print(f"     {model_name} RESULTS")
    print("==============================")
    print(f"Accuracy: {accuracy:.4f}")
    print("\nClassification Report:\n")
    print(report)
    print("Confusion Matrix:")
    print(conf_matrix)
    print("====================================\n")

    # Save metrics as table and image
    report_str = str(report)
    cm_str = np.array2string(conf_matrix, separator=', ')

    table = [
        ["Accuracy", f"{accuracy:.4f}"],
        ["Classification Report", report_str],
        ["Confusion Matrix", cm_str]
    ]

    # Save to text file
    with open(f'{model_name}_metrics.txt', 'w') as f:
        f.write(tabulate(table, headers=["Metric", "Value"], tablefmt="grid"))

    # Save table as image
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.axis('tight')
    ax.axis('off')
    ax.table(cellText=table, colLabels=["Metric", "Value"], cellLoc='left', loc='center')
    plt.savefig(f'{model_name}_metrics.jpg', bbox_inches='tight')
    plt.close()

    # Save confusion matrix image
    plt.figure(figsize=(6, 5))
    plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title(f'Confusion Matrix - {model_name}')
    plt.colorbar()
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.savefig(f'{model_name}_confusion_matrix.jpg')
    plt.close()

# ------------------- Evaluate SVM -------------------
evaluate_and_report(y_test, svm_pred, "SVM")

"""quantum svm"""

!pip install qiskit qiskit-machine-learning qiskit-aer

# ------------------- Installer Qiskit si nécessaire -------------------
!pip install qiskit qiskit-machine-learning qiskit-aer --quiet

# ------------------- Imports -------------------
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from tabulate import tabulate
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from qiskit.providers.aer import AerSimulator
from qiskit.utils import QuantumInstance
from qiskit_machine_learning.kernels import FidelityQuantumKernel

# ------------------- Load dataset -------------------
dataset = pd.read_csv('/content/drive/MyDrive/mems_dataset.csv')
X = dataset[['x', 'y', 'z']].values
y = dataset['label'].values

# Optional: convert labels to {-1, 1} if binary classification
if len(np.unique(y)) == 2:
    y = 2*y - 1

# Split dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# ------------------- Quantum Kernel -------------------
backend = AerSimulator(method='statevector')
qi = QuantumInstance(backend)
qkernel = FidelityQuantumKernel(quantum_instance=qi)

# Compute kernel matrices
K_train = qkernel.evaluate(X_train, X_train)
K_test = qkernel.evaluate(X_test, X_train)

# ------------------- Classical SVM with precomputed kernel -------------------
clf = SVC(kernel="precomputed")
clf.fit(K_train, y_train)
y_pred = clf.predict(K_test)

# ------------------- Evaluation Function -------------------
def evaluate_and_save(y_true, y_pred, model_name="Quantum_SVM"):
    # Metrics
    acc = accuracy_score(y_true, y_pred)
    report = classification_report(y_true, y_pred)
    cm = confusion_matrix(y_true, y_pred)

    # Print
    print(f"\n===== {model_name} RESULTS =====")
    print(f"Accuracy: {acc:.4f}\n")
    print("Classification Report:\n", report)
    print("Confusion Matrix:\n", cm)

    # Save metrics in .txt
    table = [
        ["Accuracy", f"{acc:.4f}"],
        ["Classification Report", report],
        ["Confusion Matrix", np.array2string(cm, separator=', ')]
    ]

    with open(f"{model_name}_metrics.txt", "w") as f:
        f.write(tabulate(table, headers=["Metric", "Value"], tablefmt="grid"))

    # Save table as image
    fig, ax = plt.subplots(figsize=(10,6))
    ax.axis('tight')
    ax.axis('off')
    ax.table(cellText=table, colLabels=["Metric", "Value"], cellLoc='left', loc='center')
    plt.savefig(f"{model_name}_metrics.jpg", bbox_inches='tight')
    plt.close()

    # Save confusion matrix image
    plt.figure(figsize=(6,5))
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title(f"Confusion Matrix - {model_name}")
    plt.colorbar()
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.savefig(f"{model_name}_confusion_matrix.jpg")
    plt.close()

# ------------------- Evaluate -------------------
evaluate_and_save(y_test, y_pred, "Quantum_SVM")

"""##task1-3



"""



import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier, VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from mlxtend.classifier import StackingClassifier
import matplotlib.pyplot as plt
from tabulate import tabulate

# Load your dataset (replace 'your_dataset.csv' with your actual dataset file)
# Assuming your dataset is in CSV format with columns 'x', 'y', 'z', and 'label'
dataset = pd.read_csv('/content/drive/MyDrive/mems_dataset.csv')

# Extract features (X) and labels (y)
X = dataset[['x', 'y', 'z']].values
y = dataset['label'].values

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Bagging


bagging_classifier = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42)
bagging_classifier.fit(X_train, y_train)
bagging_pred = bagging_classifier.predict(X_test)

# AdaBoost


adaboost_classifier = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1), n_estimators=100, random_state=42)
adaboost_classifier.fit(X_train, y_train)
adaboost_pred = adaboost_classifier.predict(X_test)

# Random Forest
random_forest_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
random_forest_classifier.fit(X_train, y_train)
random_forest_pred = random_forest_classifier.predict(X_test)

# Stacking
stacking_classifier = StackingClassifier(classifiers=[bagging_classifier, adaboost_classifier, random_forest_classifier],
                                         meta_classifier=LogisticRegression(), use_probas=True)
stacking_classifier.fit(X_train, y_train)
stacking_pred = stacking_classifier.predict(X_test)

# Blending (Manual Implementation)
base_learners = [bagging_classifier, adaboost_classifier, random_forest_classifier]
blend_pred = np.zeros((len(X_test), 3))  # Assuming 3 classes
for base_learner in base_learners:
    base_learner.fit(X_train, y_train)
    blend_pred += base_learner.predict_proba(X_test)
blend_pred = np.argmax(blend_pred, axis=1) + 1  # Convert to class labels

# Voting
voting_classifier = VotingClassifier(estimators=[('bagging', bagging_classifier),
                                                 ('adaboost', adaboost_classifier),
                                                 ('random_forest', random_forest_classifier)],
                                     voting='hard')
voting_classifier.fit(X_train, y_train)
voting_pred = voting_classifier.predict(X_test)



# Evaluate and report metrics
def evaluate_and_report(y_true, y_pred, ensemble_name):
    accuracy = accuracy_score(y_true, y_pred)
    report = classification_report(y_true, y_pred)
    conf_matrix = confusion_matrix(y_true, y_pred)
    ###

    # Convert confusion matrix to readable string
    cm_str = np.array2string(conf_matrix, separator=', ')
    # Create a table from metrics
    table = [
       # ["Accuracy", accuracy],
        ["Accuracy", f"{accuracy:.4f}"],
        ["Classification Report", report],
        ["Confusion Matrix", cm_str]
    ]

    # Save the table as a text file
    with open(f'{ensemble_name}_metrics.txt', 'w') as f:
        f.write(tabulate(table, headers=["Metric", "Value"], tablefmt="grid"))

    # Create a figure for the table and save it as an image
    fig, ax = plt.subplots(figsize=(8, 6))
    ax.axis('tight')
    ax.axis('off')
    table = ax.table(cellText=table, colLabels=["Metric", "Value"], cellLoc='center', loc='center')
    table.auto_set_font_size(False)
    table.set_fontsize(12)
    table.scale(1.5, 5)  # Adjust the table size as needed

    # Save the table as a JPG file
    plt.savefig(f'{ensemble_name}_metrics.jpg', bbox_inches='tight', pad_inches=0.1)
    plt.close()

    print(f"Metrics for {ensemble_name}:")
    print(f"Accuracy: {accuracy:.2f}")
    print("Classification Report:")
    print(report)
    print("Confusion Matrix:")
    print(conf_matrix)
    print("\n")

    # Save the confusion matrix as a JPG file
    plt.figure(figsize=(8, 6))
    plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title(f'Confusion Matrix - {ensemble_name}')
    plt.colorbar()
    plt.xticks(np.arange(3), ['Class 1', 'Class 2', 'Class 3'])
    plt.yticks(np.arange(3), ['Class 1', 'Class 2', 'Class 3'])
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.savefig(f'{ensemble_name}_confusion_matrix.jpg')
    plt.close()

# Evaluate and report metrics for each ensemble method
evaluate_and_report(y_test, bagging_pred, "Bagging")
evaluate_and_report(y_test, adaboost_pred, "AdaBoost")
evaluate_and_report(y_test, random_forest_pred, "Random Forest")
evaluate_and_report(y_test, stacking_pred, "Stacking")
evaluate_and_report(y_test, blend_pred, "Blending")
evaluate_and_report(y_test, voting_pred, "Voting")

"""##dnn metrics"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix
import tensorflow as tf
from tensorflow import keras
import shap

# Load your dataset
df= pd.read_csv('/content/drive/MyDrive/mems_dataset.csv')

# Assuming the columns in your CSV are named 'x', 'y', 'z', and 'label'
X = df[['x', 'y', 'z']]
y = df['label']

# Remap labels to start from 0
label_mapping = {1: 0, 2: 1, 3: 2}
y = y.map(label_mapping)

# Split the data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Define the DNN model
model = keras.Sequential([
    keras.layers.Dense(64, activation='relu', input_shape=(3,)),
    keras.layers.Dense(64, activation='relu'),
    keras.layers.Dense(3, activation='softmax')
])

# Compile the model
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)

# Evaluate the model on test data
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)

# Generate and save the confusion matrix as a JPG file
confusion_mat = confusion_matrix(y_test, y_pred_classes)
plt.figure(figsize=(8, 6))
sns.heatmap(confusion_mat, annot=True, fmt="d", cmap="Blues")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix")
plt.savefig("confusion_matrix.jpg")
plt.close()

# Generate classification report
classification_rep = classification_report(y_test, y_pred_classes)
print(classification_rep)

"""##ensemble metrics"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier, VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from mlxtend.classifier import StackingClassifier
import matplotlib.pyplot as plt
from tabulate import tabulate

# Load your dataset (replace 'your_dataset.csv' with your actual dataset file)
# Assuming your dataset is in CSV format with columns 'x', 'y', 'z', and 'label'
dataset = pd.read_csv('/content/drive/MyDrive/mems_dataset.csv')

# Extract features (X) and labels (y)
X = dataset[['x', 'y', 'z']].values
y = dataset['label'].values

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Bagging
bagging_classifier = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42)
bagging_classifier.fit(X_train, y_train)
bagging_pred = bagging_classifier.predict(X_test)

# AdaBoost
adaboost_classifier = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1), n_estimators=100, random_state=42)
adaboost_classifier.fit(X_train, y_train)
adaboost_pred = adaboost_classifier.predict(X_test)

# Random Forest
random_forest_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
random_forest_classifier.fit(X_train, y_train)
random_forest_pred = random_forest_classifier.predict(X_test)

# Stacking
stacking_classifier = StackingClassifier(classifiers=[bagging_classifier, adaboost_classifier, random_forest_classifier],
                                         meta_classifier=LogisticRegression(), use_probas=True)
stacking_classifier.fit(X_train, y_train)
stacking_pred = stacking_classifier.predict(X_test)

# Blending (Manual Implementation)
base_learners = [bagging_classifier, adaboost_classifier, random_forest_classifier]
blend_pred = np.zeros((len(X_test), 3))  # Assuming 3 classes
for base_learner in base_learners:
    base_learner.fit(X_train, y_train)
    blend_pred += base_learner.predict_proba(X_test)
blend_pred = np.argmax(blend_pred, axis=1) + 1  # Convert to class labels

# Voting
voting_classifier = VotingClassifier(estimators=[('bagging', bagging_classifier),
                                                 ('adaboost', adaboost_classifier),
                                                 ('random_forest', random_forest_classifier)],
                                     voting='hard')
voting_classifier.fit(X_train, y_train)
voting_pred = voting_classifier.predict(X_test)
"""
# Evaluate and report metrics
def evaluate_and_report(y_true, y_pred, ensemble_name):
    accuracy = accuracy_score(y_true, y_pred)
    report = classification_report(y_true, y_pred)
    conf_matrix = confusion_matrix(y_true, y_pred)
  # Convert confusion matrix to readable string
    report_str = str(report)
    cm_str = np.array2string(conf_matrix, separator=', ')
    # Create a table from metrics
    table = [
        ["Accuracy", accuracy],
        ["Classification Report", report],
        ["Confusion Matrix", conf_matrix]
    ]

    # Save the table as a text file
    with open(f'{ensemble_name}_metrics.txt', 'w') as f:
        f.write(tabulate(table, headers=["Metric", "Value"], tablefmt="grid"))

    # Create a figure for the table and save it as an image
    fig, ax = plt.subplots(figsize=(8, 6))
    ax.axis('tight')
    ax.axis('off')
    table = ax.table(cellText=table, colLabels=["Metric", "Value"], cellLoc='center', loc='center')
    table.auto_set_font_size(False)
    table.set_fontsize(12)
    table.scale(1.5, 5)  # Adjust the table size as needed

    # Save the table as a JPG file
    plt.savefig(f'{ensemble_name}_metrics.jpg', bbox_inches='tight', pad_inches=0.1)
    plt.close()

    # print(f"Metrics for {ensemble_name}:")
    # print(f"Accuracy: {accuracy:.2f}")
    # print("Classification Report:")
    # print(report)
    # print("Confusion Matrix:")
    # print(conf_matrix)
    # print("\n")

    # Save the confusion matrix as a JPG file
    plt.figure(figsize=(8, 6))
    plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title(f'Confusion Matrix - {ensemble_name}')
    plt.colorbar()
    plt.xticks(np.arange(3), ['Class 1', 'Class 2', 'Class 3'])
    plt.yticks(np.arange(3), ['Class 1', 'Class 2', 'Class 3'])
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.savefig(f'{ensemble_name}_confusion_matrix.jpg')
    plt.close()
"""

def evaluate_and_report(y_true, y_pred, ensemble_name):
    accuracy = accuracy_score(y_true, y_pred)
    report = classification_report(y_true, y_pred)
    conf_matrix = confusion_matrix(y_true, y_pred)

    # Convertir en string
    report_str = str(report)
    cm_str = np.array2string(conf_matrix, separator=', ')

    # Tableau compatible tabulate
    table = [
        ["Accuracy", f"{accuracy:.4f}"],
        ["Classification Report", report_str],
        ["Confusion Matrix", cm_str]
    ]

    # Sauvegarde fichier texte
    with open(f'{ensemble_name}_metrics.txt', 'w') as f:
        f.write(tabulate(table, headers=["Metric", "Value"], tablefmt="grid"))

    # Image tableau
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.axis('tight')
    ax.axis('off')
    ax.table(cellText=table, colLabels=["Metric", "Value"], cellLoc='left', loc='center')
    plt.savefig(f'{ensemble_name}_metrics.jpg', bbox_inches='tight', pad_inches=0.1)
    plt.close()

    # Confusion matrix image
    plt.figure(figsize=(6, 5))
    plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title(f'Confusion Matrix - {ensemble_name}')
    plt.colorbar()
    plt.xticks(np.arange(conf_matrix.shape[0]))
    plt.yticks(np.arange(conf_matrix.shape[0]))
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.savefig(f'{ensemble_name}_confusion_matrix.jpg')
    plt.close()
    plt.show()

# Evaluate and report metrics for each ensemble method
evaluate_and_report(y_test, bagging_pred, "Bagging")
evaluate_and_report(y_test, adaboost_pred, "AdaBoost")
evaluate_and_report(y_test, random_forest_pred, "Random Forest")
evaluate_and_report(y_test, stacking_pred, "Stacking")
evaluate_and_report(y_test, blend_pred, "Blending")
evaluate_and_report(y_test, voting_pred, "Voting")

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier, VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from mlxtend.classifier import StackingClassifier
import matplotlib.pyplot as plt
from tabulate import tabulate

# Load your dataset (replace 'your_dataset.csv' with your actual dataset file)
# Assuming your dataset is in CSV format with columns 'x', 'y', 'z', and 'label'
dataset = pd.read_csv('/content/drive/MyDrive/mems_dataset.csv')

# Extract features (X) and labels (y)
X = dataset[['x', 'y', 'z']].values
y = dataset['label'].values

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Bagging
bagging_classifier = BaggingClassifier(estimator=DecisionTreeClassifier(), n_estimators=100, random_state=42)
bagging_classifier.fit(X_train, y_train)
bagging_pred = bagging_classifier.predict(X_test)

# AdaBoost
adaboost_classifier = AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1), n_estimators=100, random_state=42)
adaboost_classifier.fit(X_train, y_train)
adaboost_pred = adaboost_classifier.predict(X_test)

# Random Forest
random_forest_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
random_forest_classifier.fit(X_train, y_train)
random_forest_pred = random_forest_classifier.predict(X_test)

# Stacking
stacking_classifier = StackingClassifier(classifiers=[bagging_classifier, adaboost_classifier, random_forest_classifier],
                                         meta_classifier=LogisticRegression(), use_probas=True)
stacking_classifier.fit(X_train, y_train)
stacking_pred = stacking_classifier.predict(X_test)

# Blending (Manual Implementation)
base_learners = [bagging_classifier, adaboost_classifier, random_forest_classifier]
blend_pred = np.zeros((len(X_test), 3))  # Assuming 3 classes
for base_learner in base_learners:
    base_learner.fit(X_train, y_train)
    blend_pred += base_learner.predict_proba(X_test)
blend_pred = np.argmax(blend_pred, axis=1) + 1  # Convert to class labels

# Voting
voting_classifier = VotingClassifier(estimators=[('bagging', bagging_classifier),
                                                 ('adaboost', adaboost_classifier),
                                                 ('random_forest', random_forest_classifier)],
                                     voting='hard')
voting_classifier.fit(X_train, y_train)
voting_pred = voting_classifier.predict(X_test)


def evaluate_and_report(y_true, y_pred, ensemble_name):
    accuracy = accuracy_score(y_true, y_pred)
    report = classification_report(y_true, y_pred)
    conf_matrix = confusion_matrix(y_true, y_pred)

    # ---- AFFICHAGE DANS COLAB ----
    print("\n\n==============================")
    print(f"     {ensemble_name} RESULTS")
    print("==============================")
    print(f"Accuracy: {accuracy:.4f}")
    print("\nClassification Report:\n")
    print(report)
    print("Confusion Matrix:")
    print(conf_matrix)
    print("====================================\n")

    # Conversion string pour tabulate
    report_str = str(report)
    cm_str = np.array2string(conf_matrix, separator=', ')

    table = [
        ["Accuracy", f"{accuracy:.4f}"],
        ["Classification Report", report_str],
        ["Confusion Matrix", cm_str]
    ]

    # Save .txt
    with open(f'{ensemble_name}_metrics.txt', 'w') as f:
        f.write(tabulate(table, headers=["Metric", "Value"], tablefmt="grid"))

    # Save table image
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.axis('tight')
    ax.axis('off')
    ax.table(cellText=table, colLabels=["Metric", "Value"], cellLoc='left', loc='center')
    plt.savefig(f'{ensemble_name}_metrics.jpg', bbox_inches='tight')
    plt.close()

    # Save confusion matrix image
    plt.figure(figsize=(6, 5))
    plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title(f'Confusion Matrix - {ensemble_name}')
    plt.colorbar()
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.savefig(f'{ensemble_name}_confusion_matrix.jpg')
    plt.close()


# Evaluate and report metrics for each ensemble method
evaluate_and_report(y_test, bagging_pred, "Bagging")
evaluate_and_report(y_test, adaboost_pred, "AdaBoost")
evaluate_and_report(y_test, random_forest_pred, "Random Forest")
evaluate_and_report(y_test, stacking_pred, "Stacking")
evaluate_and_report(y_test, blend_pred, "Blending")
evaluate_and_report(y_test, voting_pred, "Voting")

"""##mems combinaition metrics xy xz yz

"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.neural_network import MLPClassifier

# Load your dataset
data = pd.read_csv('/content/drive/MyDrive/mems_dataset.csv')

# Split the data into features (X) and labels (y)
X = data[['x', 'y']]
y = data['label']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create a dictionary to store model names and the corresponding model objects
models = {
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier(),
    'AdaBoost': AdaBoostClassifier(),
    'SVM': SVC(),
    'Deep Neural Network': MLPClassifier(random_state=42)
}

# Initialize an empty DataFrame to store performance metrics
metrics_df = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])


# Iterate through the models and calculate performance metrics
for model_name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')

    # ✅ Remplacement de .append() par pd.concat()
    new_row = pd.DataFrame([{
        'Model': model_name,
        'Accuracy': accuracy,
        'Precision': precision,
        'Recall': recall,
        'F1 Score': f1
    }])
    metrics_df = pd.concat([metrics_df, new_row], ignore_index=True)


# Print the performance metrics table
print(metrics_df)

# Create a table image using matplotlib
plt.figure(figsize=(10, 6))
plt.axis('off')  # Turn off axis
plt.table(cellText=metrics_df.values, colLabels=metrics_df.columns, cellLoc='center', loc='center', colColours=['#f2f2f2']*len(metrics_df.columns))
plt.tight_layout()

# Save the table as a JPG image
plt.savefig('mems_xy_metrics.jpg', format='jpg')

# Display the table
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.neural_network import MLPClassifier

# Load your dataset
data = pd.read_csv('/content/drive/MyDrive/mems_dataset.csv')

# Split the data into features (X) and labels (y)
X = data[['x', 'z']]
y = data['label']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create a dictionary to store model names and the corresponding model objects
models = {
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier(),
    'AdaBoost': AdaBoostClassifier(),
    'SVM': SVC(),
    'Deep Neural Network': MLPClassifier(random_state=42)
}

# Initialize an empty DataFrame to store performance metrics
metrics_df = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])


# Iterate through the models and calculate performance metrics
for model_name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')

    # ✅ Remplacement de .append() par pd.concat()
    new_row = pd.DataFrame([{
        'Model': model_name,
        'Accuracy': accuracy,
        'Precision': precision,
        'Recall': recall,
        'F1 Score': f1
    }])
    metrics_df = pd.concat([metrics_df, new_row], ignore_index=True)


# Print the performance metrics table
print(metrics_df)

# Create a table image using matplotlib
plt.figure(figsize=(10, 6))
plt.axis('off')  # Turn off axis
plt.table(cellText=metrics_df.values, colLabels=metrics_df.columns, cellLoc='center', loc='center', colColours=['#f2f2f2']*len(metrics_df.columns))
plt.tight_layout()

# Save the table as a JPG image
plt.savefig('mems_xy_metrics.jpg', format='jpg')

# Display the table
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.neural_network import MLPClassifier

# Load your dataset
data = pd.read_csv('/content/drive/MyDrive/mems_dataset.csv')

# Split the data into features (X) and labels (y)
X = data[['y', 'z']]
y = data['label']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create a dictionary to store model names and the corresponding model objects
models = {
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier(),
    'AdaBoost': AdaBoostClassifier(),
    'SVM': SVC(),
    'Deep Neural Network': MLPClassifier(random_state=42)
}

# Initialize an empty DataFrame to store performance metrics
metrics_df = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])


# Iterate through the models and calculate performance metrics
for model_name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')

    # ✅ Remplacement de .append() par pd.concat()
    new_row = pd.DataFrame([{
        'Model': model_name,
        'Accuracy': accuracy,
        'Precision': precision,
        'Recall': recall,
        'F1 Score': f1
    }])
    metrics_df = pd.concat([metrics_df, new_row], ignore_index=True)


# Print the performance metrics table
print(metrics_df)

# Create a table image using matplotlib
plt.figure(figsize=(10, 6))
plt.axis('off')  # Turn off axis
plt.table(cellText=metrics_df.values, colLabels=metrics_df.columns, cellLoc='center', loc='center', colColours=['#f2f2f2']*len(metrics_df.columns))
plt.tight_layout()

# Save the table as a JPG image
plt.savefig('mems_xy_metrics.jpg', format='jpg')

# Display the table
plt.show()

"""## metrics"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import (
    classification_report,
    accuracy_score,
    balanced_accuracy_score,
    matthews_corrcoef,
    roc_auc_score,
)
from tabulate import tabulate

def load_data(file_path, selected_features):
    data = pd.read_csv(file_path)
    data.fillna(data.select_dtypes(include=[np.number]).mean(), inplace=True)
    data = data[selected_features]
    return data

def preprocess_data(data, target_column):
    X = data.drop(columns=[target_column])
    y = data[target_column]

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    label_encoder = LabelEncoder()
    y_train_encoded = label_encoder.fit_transform(y_train)
    y_test_encoded = label_encoder.transform(y_test)

    return X_train, X_test, y_train_encoded, y_test_encoded, label_encoder

def evaluate_model(model, X_test, y_test_encoded):
    predictions = model.predict(X_test)
    accuracy = accuracy_score(y_test_encoded, predictions)
    bacc = balanced_accuracy_score(y_test_encoded, predictions)
    mcc = matthews_corrcoef(y_test_encoded, predictions)

    return predictions, accuracy, bacc, mcc

def calculate_auc_roc(model, X_test, y_test_encoded, label_encoder):
    probabilities = model.predict_proba(X_test)
    auc_roc_values = []

    for class_idx in range(len(label_encoder.classes_)):
        class_probabilities = probabilities[:, class_idx]
        class_indicator = (y_test_encoded == class_idx).astype(int)
        class_auc_roc = roc_auc_score(class_indicator, class_probabilities)
        auc_roc_values.append(class_auc_roc)

    avg_auc_roc = sum(auc_roc_values) / len(auc_roc_values)
    return avg_auc_roc

def main():
    # Load data
    selected_features = ['x', 'y', 'z', 'label']
    piezoelectric_data = load_data('/content/drive/MyDrive/mems_dataset.csv', selected_features)

    # Preprocess data
    X_train, X_test, y_train_encoded, y_test_encoded, label_encoder = preprocess_data(piezoelectric_data, 'label')

    # Initialize models
    knn_classifier = KNeighborsClassifier(n_neighbors=5)
    ada_classifier = AdaBoostClassifier(n_estimators=50)
    svm_classifier = SVC(kernel='linear', C=1.0, probability=True)
    mlp_classifier = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=1000)

    # Train models
    knn_classifier.fit(X_train, y_train_encoded)
    ada_classifier.fit(X_train, y_train_encoded)
    svm_classifier.fit(X_train, y_train_encoded)
    mlp_classifier.fit(X_train, y_train_encoded)

    # Evaluate models
    results = []
    models = [
        ("K-Nearest Neighbors (KNN)", knn_classifier),
        ("Adaptive Boosting (ADA)", ada_classifier),
        ("Support Vector Machine (SVM)", svm_classifier),
        ("Multi-Layer Perceptron (MLP)", mlp_classifier),
    ]

    for model_name, model in models:
        predictions, accuracy, bacc, mcc = evaluate_model(model, X_test, y_test_encoded)
        auc_roc = calculate_auc_roc(model, X_test, y_test_encoded, label_encoder)
        report = classification_report(y_test_encoded, predictions, output_dict=True)

        results.append([model_name, accuracy, bacc, mcc, auc_roc, report])

    # Display results in a table
    table_headers = ["Model", "Accuracy", "Balanced Accuracy", "MCC", "AUC-ROC", "Precision", "Recall", "F1-Score"]
    table_data = [
        [model_name, accuracy, bacc, mcc, auc_roc, report['weighted avg']['precision'], report['weighted avg']['recall'], report['weighted avg']['f1-score']]
        for model_name, accuracy, bacc, mcc, auc_roc, report in results
    ]

    print(tabulate(table_data, headers=table_headers, tablefmt='grid'))

if __name__ == "__main__":
    main()

"""## SHAP global"""

# #!/bin/bash

# #SBATCH -J Task1_job
# #SBATCH -p gpu
# #SBATCH -A r00381
# #SBATCH -o task1_output.txt
# #SBATCH -e task1_error.err
# #SBATCH --mail-type=ALL
# #SBATCH --mail-user=agummadi@iu.edu
# #SBATCH --nodes=1
# #SBATCH --ntasks-per-node=5
# #SBATCH --gpus-per-node=5
# #SBATCH --time=06:00:00

# import pandas as pd
# import numpy as np
# from sklearn.model_selection import train_test_split
# from sklearn.preprocessing import StandardScaler, LabelEncoder
# import tensorflow as tf
# import shap
# from sklearn.impute import SimpleImputer


import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
import tensorflow as tf
import shap
from sklearn.impute import SimpleImputer
import matplotlib.pyplot as plt

# Load the MEMS dataset
mems_data = pd.read_csv('/content/drive/MyDrive/mems_dataset.csv')

# Data Cleaning
imputer = SimpleImputer(strategy="mean")
mems_data.fillna(mems_data.select_dtypes(include=[np.number]).mean(), inplace=True)

# Feature Selection
selected_mems_features = ["x", "y", "z", "label"]

mems_data = mems_data[selected_mems_features]

# Data Splitting
X = mems_data[["x", "y", "z"]]
y = mems_data["label"]

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# Normalization (Standardization)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Encode the machine health condition labels
label_encoder = LabelEncoder()
y_train_encoded = label_encoder.fit_transform(y_train)
y_test_encoded = label_encoder.transform(y_test)

# Build a simple Keras neural network model
model = tf.keras.Sequential(
    [
        tf.keras.layers.Input(shape=(3,)),
        tf.keras.layers.Dense(64, activation="relu"),
        tf.keras.layers.Dense(3, activation="softmax"),
    ]
)

# Compile the model
model.compile(
    optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"]
)

# Train the model
model.fit(
    X_train,
    y_train_encoded,
    epochs=10,
    batch_size=32,
    validation_data=(X_test, y_test_encoded),
)

# SHAP Feature Importance Analysis using KernelExplainer
explainer = shap.KernelExplainer(model.predict, X_train)
shap_values = explainer.shap_values(X_test)

# Rename the class labels
class_labels = ["Normal", "Near-failure", "Failure"]

# Create a summary plot of SHAP feature importance with custom class labels
shap.summary_plot(
    shap_values,
    X_test,
    feature_names=selected_mems_features[:-1],
    class_names=class_labels,
)

# Save the SHAP summary plot as a JPEG image
plt.savefig("task1_mems_output.jpg")  # Save the plot as "task1_mems_output.jpg"

"""## SHAP global for each rpm"""

# -*- coding: utf-8 -*-
"""Task 2.ipynb

Automatically generated by Colaboratory.

Original file is located at
  https://colab.research.google.com/drive/1U6520Ay2YcUfTitMnpVWapnQ9xNaklHH

**Installing required Libraries**
"""

!pip install pandas numpy scikit-learn tensorflow shap

"""# **SHAP Global Summary Plot for each RPM for Mems Dataset**"""

import pandas as pd
import numpy as np
import tensorflow as tf
import shap
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.impute import SimpleImputer

def load_and_preprocess_data(filename):
    # Load the dataset
    mems_data = pd.read_csv(filename)

    # Data Cleaning
    imputer = SimpleImputer(strategy='mean')
    mems_data.fillna(mems_data.mean(), inplace=True)

    # Feature Selection
    selected_mems_features = ['x', 'y', 'z', 'label']
    mems_data = mems_data[selected_mems_features]

    # Data Splitting
    X = mems_data[['x', 'y', 'z']]
    y = mems_data['label']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Normalization (Standardization)
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    # Encode the machine health condition labels
    label_encoder = LabelEncoder()
    y_train_encoded = label_encoder.fit_transform(y_train)
    y_test_encoded = label_encoder.transform(y_test)

    return X_train, X_test, y_train_encoded, y_test_encoded, selected_mems_features

def build_and_train_model(X_train, y_train_encoded):
    # Build a simple Keras neural network model
    model = tf.keras.Sequential([
        tf.keras.layers.Input(shape=(3,)),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dense(3, activation='softmax')
    ])

    # Compile the model
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

    # Train the model
    model.fit(X_train, y_train_encoded, epochs=10, batch_size=32)

    return model

def shap_analysis(model, X_train, X_test, selected_mems_features):
    # SHAP Feature Importance Analysis using KernelExplainer
    explainer = shap.KernelExplainer(model.predict, X_train)
    shap_values = explainer.shap_values(X_test)

    # Rename the class labels
    class_labels = ['Normal', 'Near-failure', 'Failure']

    # Create a summary plot of SHAP feature importance with custom class labels
    shap.summary_plot(shap_values, X_test, feature_names=selected_mems_features[:-1], class_names=class_labels)

if __name__ == "__main__":
    # List of dataset filenames
    dataset_files = ['mem_100.csv', 'mem_200.csv', 'mem_300.csv',
                     'mem_400.csv', 'mem_500.csv', 'mem_600.csv']

    for dataset_file in dataset_files:
        X_train, X_test, y_train_encoded, y_test_encoded, selected_mems_features = load_and_preprocess_data(dataset_file)
        model = build_and_train_model(X_train, y_train_encoded)
        shap_analysis(model, X_train, X_test, selected_mems_features)

"""# **SHAP Global Summary Plot for each RPM for Piezoelectric Dataset**"""

import pandas as pd
import numpy as np
import tensorflow as tf
import shap
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.impute import SimpleImputer

def load_and_preprocess_data(filename):
    # Load the dataset
    piezo_data = pd.read_csv(filename)

    # Data Cleaning
    imputer = SimpleImputer(strategy='mean')
    piezo_data.fillna(piezo_data.mean(), inplace=True)

    # Feature Selection
    selected_piezo_features = ['x', 'y', 'z', 'label']
    piezo_data = piezo_data[selected_piezo_features]

    # Data Splitting
    X = piezo_data[['x', 'y', 'z']]
    y = piezo_data['label']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Normalization (Standardization)
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    # Encode the machine health condition labels
    label_encoder = LabelEncoder()
    y_train_encoded = label_encoder.fit_transform(y_train)
    y_test_encoded = label_encoder.transform(y_test)

    return X_train, X_test, y_train_encoded, y_test_encoded, selected_piezo_features

def build_and_train_model(X_train, y_train_encoded):
    # Build a simple Keras neural network model
    model = tf.keras.Sequential([
        tf.keras.layers.Input(shape=(3,)),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dense(3, activation='softmax')
    ])

    # Compile the model
    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

    # Train the model
    model.fit(X_train, y_train_encoded, epochs=10, batch_size=32)

    return model

def shap_analysis(model, X_train, X_test, selected_piezo_features):
    # SHAP Feature Importance Analysis using KernelExplainer
    explainer = shap.KernelExplainer(model.predict, X_train)
    shap_values = explainer.shap_values(X_test)

    # Rename the class labels
    class_labels = ['Normal', 'Near-Failure', 'Failure']

    # Create a summary plot of SHAP feature importance with custom class labels
    shap.summary_plot(shap_values, X_test, feature_names=selected_piezo_features[:-1], class_names=class_labels)

if __name__ == "__main__":
    # List of dataset filenames for Piezoelectric Dataset
    dataset_files = ['piezo_100.csv', 'piezo_200.csv', 'piezo_300.csv',
                     'piezo_400.csv', 'piezo_500.csv', 'piezo_600.csv']

    for dataset_file in dataset_files:
        X_train, X_test, y_train_encoded, y_test_encoded, selected_piezo_features = load_and_preprocess_data(dataset_file)
        model = build_and_train_model(X_train, y_train_encoded)
        shap_analysis(model, X_train, X_test, selected_piezo_features)

"""#features importance

##lime
"""

!pip install lime

import pandas as pd
import lime
import lime.lime_tabular
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
import numpy as np

# Load your dataset
dataset = pd.read_csv('/content/drive/MyDrive/mems_dataset.csv')

# Split the dataset into features (X) and labels (y)
X = dataset[['x', 'y', 'z']]
y = dataset['label']

# Create and train a RandomForestClassifier
your_classifier = RandomForestClassifier()
your_classifier.fit(X, y)

# Define a custom LimeTabularExplainer with feature_names
class CustomLimeTabularExplainer(lime.lime_tabular.LimeTabularExplainer):
    def __init__(self, training_data, mode="classification"):
        super().__init__(training_data, mode=mode, training_labels=None)
        self.feature_names = ['x', 'y', 'z']  # Set the feature names explicitly

# Create a custom LIME explainer
explainer = CustomLimeTabularExplainer(X.values, mode="classification")

# Initialize lists to store sample indices for each label
sample_indices = []

# Loop over unique labels (1, 2, 3)
for label in [1, 2, 3]:
    # Get indices of samples with the current label
    label_indices = np.where(y == label)[0]

    # Take one sample with the current label (if available)
    if len(label_indices) > 0:
        sample_index = label_indices[0]
        sample_indices.append(sample_index)

# Explain predictions for the selected samples
for sample_index in sample_indices:
    test_instance = X.iloc[sample_index]


    # Generate explanations
    # explanation = explainer.explain_instance(
    #     test_instance.values,
    #     your_classifier.predict_proba,  # Use predict_proba for classification
    #     num_features=len(X.columns),
    #     # feature_names = list(X.columns.values)
    # )

    explainer = lime.lime_tabular.LimeTabularExplainer(X.to_numpy(),feature_names = list(X.columns.values), discretize_continuous=True)

#  explainer = lime.lime_tabular.LimeTabularExplainer(X.to_numpy(),feature_names = list(X.columns.values),class_names= y.values, discretize_continuous=True)

    exp = explainer.explain_instance(test_instance, your_classifier.predict_proba, num_features=3, top_labels=3)

    exp.show_in_notebook(show_table=True, show_all=True)


    #lime list to string

    lime_list = exp.as_list()

    lime_list.sort()

    plt.show()

    # Get feature importance from LIME explanation
    # feature_importance = explainer.as_list()

    # Save feature importance as a figure (e.g., a bar chart)
    # features, importance_scores = zip(*feature_importance)
    # plt.figure(figsize=(8, 6))
    # plt.barh(features, importance_scores)
    # plt.xlabel('Importance')
    # plt.ylabel('Features')
    # plt.title(f'Feature Importance from LIME (Label {y.iloc[sample_index]})')
    # plt.savefig(f'lime_feature_importance_label_{y.iloc[sample_index]}_sample_{sample_index}.jpg')

    # Save the explanation figure as a JPG
    # explanation_fig = explanation.as_pyplot_figure()
    # explanation_fig.savefig(f'lime_explanation_label_{y.iloc[sample_index]}_sample_{sample_index}.jpg')

"""##loco_features_imp"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from copy import deepcopy
import matplotlib.pyplot as plt

# Load your dataset from the CSV file
data = pd.read_csv('/content/drive/MyDrive/mems_dataset.csv')

# Separate features (X) and labels (y)
X = data[["x", "y", "z"]]
y = data["label"]

# Split the dataset into a training and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create and train a RandomForestClassifier
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Choose a specific data point for LOCO analysis (e.g., the first data point)
data_point_idx = 0
data_point = X_test.iloc[data_point_idx, :]
true_label = y_test.iloc[data_point_idx]

# Make a prediction for the chosen data point
original_prediction = rf_model.predict([data_point])[0]

# Create a copy of the model to modify for LOCO
loco_model = deepcopy(rf_model)

# Initialize an array to store prediction differences
prediction_differences = []

# Iterate through each feature and calculate prediction differences
for feature in X.columns:
    data_point_mean = X_test[feature].mean()
    data_point_copy = data_point.copy()
    data_point_copy[feature] = data_point_mean
    loco_prediction = loco_model.predict([data_point_copy])[0]
    prediction_difference = loco_prediction - original_prediction
    prediction_differences.append((feature, prediction_difference))

# Plot and save the prediction differences as a bar chart
features, differences = zip(*prediction_differences)
plt.figure(figsize=(10, 6))
plt.barh(features, differences)
plt.xlabel("Prediction Difference")
plt.ylabel("Feature")
plt.title("LOCO Prediction Differences")
plt.savefig("loco_predictions.jpg", bbox_inches="tight")
plt.show()

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt
from copy import deepcopy

# 1️⃣ Charger le dataset
data = pd.read_csv('/content/drive/MyDrive/mems_dataset.csv')

# 2️⃣ Séparer features et labels
X = data[["x", "y", "z"]]
y = data["label"]

# 3️⃣ Split train/test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 4️⃣ Entraîner un RandomForestClassifier
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# 5️⃣ Choisir un point de données pour LOCO
data_point_idx = 0
data_point = X_test.iloc[data_point_idx, :]
true_label = y_test.iloc[data_point_idx]

# Convertir en DataFrame pour éviter les warnings
data_point_df = pd.DataFrame([data_point], columns=X.columns)

# 6️⃣ Prédiction originale
original_proba = rf_model.predict_proba(data_point_df)

# 7️⃣ Créer une copie du modèle pour LOCO
loco_model = deepcopy(rf_model)

# 8️⃣ Calculer l'impact de chaque feature
prediction_differences = []

for feature in X.columns:
    data_point_copy = data_point.copy()
    # Remplacer la feature par la moyenne
    data_point_copy[feature] = X_test[feature].mean()
    data_point_copy_df = pd.DataFrame([data_point_copy], columns=X.columns)

    loco_proba = loco_model.predict_proba(data_point_copy_df)
    # Mesurer la différence en probabilités (somme des différences absolues)
    prediction_difference = np.abs(loco_proba - original_proba).sum()

    prediction_differences.append((feature, prediction_difference))

# 9️⃣ Visualiser les différences
features, differences = zip(*prediction_differences)
plt.figure(figsize=(10, 6))
plt.barh(features, differences, color='skyblue')
plt.xlabel("Prediction Difference (sum of probabilities)")
plt.ylabel("Feature")
plt.title(f"LOCO Feature Impact for data point index {data_point_idx}")
plt.savefig("loco_predictions_corrected.jpg", bbox_inches="tight")
plt.show()

"""##t2_diff

"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
import numpy as np

# Load dataset
data = pd.read_csv('/content/drive/MyDrive/mems_dataset.csv')

# Separate features (x, y, z) and labels
X = data[['x', 'y', 'z']]
y = data['label']

# Define models
random_forest_model = RandomForestClassifier()
decision_tree_model = DecisionTreeClassifier()
logistic_regression_model = LogisticRegression(max_iter=10000)
# FIX 1 (Previously applied): Use kernel='linear' to enable coef_ for SVM
svm_model = SVC(kernel='linear', probability=True)
mlp_model = MLPClassifier(max_iter=1000)
# FIX 2 (Previously applied): Use estimator instead of base_estimator for AdaBoost
ada_model = AdaBoostClassifier(estimator=DecisionTreeClassifier(), n_estimators=100)

# Fit models to the data
random_forest_model.fit(X, y)
decision_tree_model.fit(X, y)
logistic_regression_model.fit(X, y)
svm_model.fit(X, y)
mlp_model.fit(X, y)
ada_model.fit(X, y)

# Get feature importances
random_forest_feature_importances = random_forest_model.feature_importances_
decision_tree_feature_importances = decision_tree_model.feature_importances_
svm_feature_importances = np.abs(svm_model.coef_).sum(axis=0)  # Correct for Linear SVM
# FIX 3 (Previously applied): Use axis=1 to sum weights per input feature for MLP
mlp_feature_importances = np.abs(mlp_model.coefs_[0]).sum(axis=1)

# FIX 4 (New): Add the underscore (_) to access the fitted attribute
ada_feature_importances = ada_model.feature_importances_

#Plot and save feature importances for all models
def save_feature_importance_plot(feature_importances, title, filename):
    plt.figure(figsize=(8, 6))
    plt.bar(range(len(X.columns)), feature_importances)
    plt.xticks(range(len(X.columns)), X.columns, rotation=45)
    plt.title(title)
    plt.tight_layout()
    plt.savefig(filename)
    # Pour afficher le graphique dans un notebook, vous pouvez ajouter :
    plt.show()
    plt.close()

save_feature_importance_plot(random_forest_feature_importances, 'Random Forest Feature Importances', 'random_forest_feature_importance.jpg')
save_feature_importance_plot(decision_tree_feature_importances, 'Decision Tree Feature Importances', 'decision_tree_feature_importance.jpg')
save_feature_importance_plot(svm_feature_importances, 'SVM Feature Importances', 'svm_feature_importance.jpg')
save_feature_importance_plot(mlp_feature_importances, 'MLP Feature Importances', 'mlp_feature_importance.jpg')
save_feature_importance_plot(ada_feature_importances, 'AdaBoost Feature Importances', 'ada_feature_importance.jpg')

"""##svm"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.svm import SVC
import numpy as np

# Load dataset
data = pd.read_csv('/content/drive/MyDrive/mems_dataset.csv')

# Separate features (x, y, z) and labels
X = data[['x', 'y', 'z']]
y = data['label']

# Define SVM model
svm_model = SVC(kernel='linear', probability=True)  # Use a linear kernel for feature importances

# Fit SVM model to the data
svm_model.fit(X, y)
#calcul similarité
# Get feature importances (absolute values of coefficients)
svm_feature_importances = np.abs(svm_model.coef_).sum(axis=0)

# Plot and save feature importances for SVM
def save_feature_importance_plot(feature_importances, title, filename):
    plt.figure(figsize=(8, 6))
    plt.bar(range(len(X.columns)), feature_importances)
    plt.xticks(range(len(X.columns)), X.columns, rotation=45)
    plt.title(title)
    plt.tight_layout()
    plt.savefig(filename)
    plt.show()
    plt.close()

save_feature_importance_plot(svm_feature_importances, 'SVM Feature Importances', 'svm_mems_bar_feature_importance.jpg')

"""##cem"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.inspection import permutation_importance

# Load dataset
data = pd.read_csv('/content/drive/MyDrive/mems_dataset.csv')

# Extract the features (x, y, z) and labels
X = data[['x', 'y', 'z']]
y = data['label']

# Create a RandomForestClassifier
clf = RandomForestClassifier(random_state=42)

# Fit the classifier to data
clf.fit(X, y)

# Calculate feature importances using permutation importance
result = permutation_importance(clf, X, y, n_repeats=30, random_state=42)

# Get the feature importances and names
importances = result.importances_mean
feature_names = ['x', 'y', 'z']

# Create a bar plot to visualize feature importance
plt.barh(feature_names, importances)
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.title('Feature Importance using CEM')
plt.gca().invert_yaxis()  # Invert the y-axis for better visualization
plt.savefig('cem_feature_importance.jpg', format='jpg')  # Save the figure as a JPG
plt.show()

"""## dnn-feature **importance**"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score
from sklearn.inspection import permutation_importance

# Load your dataset
data = pd.read_csv('/content/drive/MyDrive/mems_dataset.csv')

# Assuming your dataset has columns 'x', 'y', 'z', and 'labels'
X = data[['x', 'y', 'z']]
y = data['label']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Standardize the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Train a neural network (DNN) model
model = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=1000, random_state=0)
model.fit(X_train, y_train)

# Calculate baseline accuracy
baseline_accuracy = accuracy_score(y_test, model.predict(X_test))

# Calculate permutation importance for each feature
result = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=0)

# Get the importance scores for each feature
importance_scores = result.importances_mean

# Print the importance scores for each feature
for feature, importance in zip(['x', 'y', 'z'], importance_scores):
    print(f"{feature} Importance: {importance:.4f}")

# You can also rank the features by importance
sorted_feature_importance = np.argsort(importance_scores)[::-1]
print("Feature ranking:", [(['x', 'y', 'z'][i], importance_scores[i]) for i in sorted_feature_importance])

# Save the output as a JPG file
plt.figure(figsize=(8, 6))
plt.bar(['x', 'y', 'z'], importance_scores)
plt.title('Feature Importance')
plt.xlabel('Features')
plt.ylabel('Importance Score')
plt.savefig('dnn_feature_importance_mems.jpg')
plt.show()

"""##mems_ale"""

!pip install reportlab

!pip install fpdf

# Install the missing library
!pip install reportlab

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

# NOTE: The imports below are not strictly necessary if you only use FPDF,
# but they are kept to resolve the ModuleNotFoundError from the original code.
from reportlab.lib.pagesizes import letter
from reportlab.lib import colors
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.graphics import renderPDF
from io import BytesIO
from reportlab.pdfgen import canvas
from fpdf import FPDF # The library actually used for PDF generation

# Load dataset
# Ensure you have uploaded 'mems_dataset.csv' to the specified path or updated the path
try:
    data = pd.read_csv('/content/drive/MyDrive/mems_dataset.csv')
except FileNotFoundError:
    print("Error: The file 'mems_dataset.csv' was not found. Please check the path.")
    # Exit or handle error appropriately
    raise

# Split your data into training and testing sets:
X = data[['x', 'y', 'z']]  # Features 'x', 'y', 'z'
y = data['label']  # Target column 'label'
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a machine learning model
model = RandomForestClassifier()
model.fit(X_train, y_train)

# Create a PDF report
class PDF(FPDF):
    def header(self):
        self.set_font('Arial', 'B', 12)
        self.cell(0, 10, 'ALE Plots and Explanations', 0, 1, 'C')
        self.ln(10)

    def chapter_title(self, title):
        self.set_font('Arial', 'B', 12)
        self.cell(0, 10, title, 0, 1, 'L')
        self.ln(4)

    def chapter_body(self, body):
        self.set_font('Arial', '', 12)
        self.multi_cell(0, 10, body)
        self.ln()


# Initialize PDF
pdf = PDF()
pdf.add_page()
features_to_plot = ['x', 'y', 'z']

# Generate and add ALE Plots
for feature_name in features_to_plot:
    plt.figure()

    # Check if a model has been trained and has the predict_proba method
    if not hasattr(model, 'predict_proba'):
        print(f"Model {type(model).__name__} does not have predict_proba. Skipping ALE plot generation.")
        continue

    # Initialize ALE plot components
    ale_data = {}
    grid_values = np.linspace(X_train[feature_name].min(), X_train[feature_name].max(), num=100)

    for class_index, class_name in enumerate(y.unique()):
        ale_values = []

        # Calculate ALE values for the current class
        for grid_point in grid_values:
            X_temp = X_test.copy()
            X_temp[feature_name] = grid_point

            # Predict probabilities for the modified dataset
            probabilities = model.predict_proba(X_temp)[:, class_index]

            # The simple averaging calculation for ALE:
            # ALE for a grid point is the average *change* in prediction
            # when the feature value is shifted to the grid point.
            # Your current implementation approximates the PDP (Partial Dependence Plot)
            # which is less accurate than a true ALE plot, but we will use
            # your existing structure to avoid introducing an entire new library (like alibi).
            ale_value = np.mean(probabilities)
            ale_values.append(ale_value)

        # Center the plot (optional but standard for ALE/PDP)
        # ale_values = np.array(ale_values) - np.mean(ale_values)

        # Plot ALE curve for the current class
        plt.plot(grid_values, ale_values, label=f'Class {class_name}')

    plt.xlabel(feature_name)
    plt.ylabel('Partial Dependence (Approximation of ALE)')
    plt.title(f'Feature Effect Plot for {feature_name}')
    plt.legend()

    # Save the plot to a temporary file
    plot_filename = f'ale_{feature_name}_plot.png' # Use PNG for better quality in FPDF
    plt.savefig(plot_filename)
    plt.close() # Close the figure to free memory

    # Add the plot and explanation to the PDF
    pdf.chapter_title(f'Feature Effect Plot for {feature_name}')
    explanation = (
        f"This plot illustrates the effect of the feature '{feature_name}' on the model's prediction probability "
        f"for each class. The x-axis shows the range of feature values, and the y-axis shows the average predicted "
        f"probability. A rising curve indicates that higher values of the feature tend to increase the probability "
        f"of that class, and vice-versa. Note: This calculation is an approximation of the Partial Dependence Plot (PDP), "
        f"which is similar in interpretation to ALE, showing the marginal effect of the feature."
    )
    pdf.chapter_body(explanation)

    # Ensure the image file is added correctly
    try:
        pdf.image(plot_filename, x=10, y=None, w=190)
    except Exception as e:
        # Handle case where image loading fails (e.g., if FPDF can't find/read the file)
        print(f"Could not add image {plot_filename} to PDF: {e}")


# Save the PDF report
pdf_filename = 'piezo_ale_report.pdf'
pdf.output(pdf_filename)

print(f"\nPDF report saved as: {pdf_filename}")
print("Check your file browser/working directory for the report and the plot images.")

"""##mems pfi"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.neural_network import MLPClassifier
from sklearn.inspection import permutation_importance

# Load your dataset
data = pd.read_csv('/content/drive/MyDrive/mems_dataset.csv')

# Split the data into features (X) and labels (y)
X = data[['x', 'y', 'z']]
y = data['label']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create a dictionary to store model names and the corresponding model objects
models = {
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier(),
    'AdaBoost': AdaBoostClassifier(),
    'SVM': SVC(),
    'Deep Neural Network': MLPClassifier(random_state=42)
}

# Initialize a directory to store PFI summary plots
pfi_plot_dir = 'mems_pfi_plots/'

# Ensure the directory exists
import os
os.makedirs(pfi_plot_dir, exist_ok=True)

# Create bar graphs for PFI summary plots
for model_name, model in models.items():
    model.fit(X_train, y_train)

    # Calculate permutation feature importance
    perm_importance = permutation_importance(model, X_test, y_test, n_repeats=30, random_state=42)

    # Get feature importance scores
    feature_importance = perm_importance.importances_mean

    # Create a bar plot to visualize feature importance
    plt.figure(figsize=(10, 6))
    feature_names = X.columns.tolist()
    plt.bar(feature_names, feature_importance, label=model_name)
    plt.xlabel('Features')
    plt.ylabel('Importance Score (Drop in Accuracy)')
    plt.title(f'PFI Feature Importance for {model_name}')
    plt.xticks(rotation=45)
    plt.legend()
    plt.tight_layout()

    # Save the PFI summary bar graph as a JPG image
    plt.savefig(os.path.join(pfi_plot_dir, f'mems_pfi_summary_{model_name}.jpg'))
    plt.close()

"""##mems_profweight"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.neural_network import MLPClassifier
from sklearn.inspection import permutation_importance

# Load your dataset
data = pd.read_csv('/content/drive/MyDrive/mems_dataset.csv')

# Split the data into features (X) and labels (y)
X = data[['x', 'y', 'z']]
y = data['label']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create a dictionary to store model names and the corresponding model objects
models = {
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier(),
    'AdaBoost': AdaBoostClassifier(),
    'SVM': SVC(),
    'Deep Neural Network': MLPClassifier(random_state=42)
}

# Initialize a directory to store PFI summary plots
pfi_plot_dir = 'mems_pfi_plots/'

# Ensure the directory exists
import os
os.makedirs(pfi_plot_dir, exist_ok=True)

# Create bar graphs for PFI summary plots
for model_name, model in models.items():
    model.fit(X_train, y_train)

    # Calculate permutation feature importance
    perm_importance = permutation_importance(model, X_test, y_test, n_repeats=30, random_state=42)

    # Get feature importance scores
    feature_importance = perm_importance.importances_mean

    # Create a bar plot to visualize feature importance
    plt.figure(figsize=(10, 6))
    feature_names = X.columns.tolist()
    plt.bar(feature_names, feature_importance, label=model_name)
    plt.xlabel('Features')
    plt.ylabel('Importance Score (Drop in Accuracy)')
    plt.title(f'PFI Feature Importance for {model_name}')
    plt.xticks(rotation=45)
    plt.legend()
    plt.tight_layout()

    # Save the PFI summary bar graph as a JPG image
    plt.savefig(os.path.join(pfi_plot_dir, f'mems_pfi_summary_{model_name}.jpg'))
    plt.show()
    plt.close()

"""##mems shap"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.neural_network import MLPClassifier
import shap

# Load your dataset
data = pd.read_csv('/content/drive/MyDrive/mems_dataset.csv')

# Split the data into features (X) and labels (y)
X = data[['x', 'y', 'z']]
y = data['label']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create a dictionary to store model names and the corresponding model objects
models = {
    # 'Decision Tree': DecisionTreeClassifier(),
    # 'Random Forest': RandomForestClassifier(),
    # 'AdaBoost': AdaBoostClassifier(),
    'SVM': SVC()
    # ,
    # 'Deep Neural Network': MLPClassifier(random_state=42)
}

# Initialize a directory to store SHAP summary plots
shap_plot_dir = 'mems_shap_plots/'

# Ensure the directory exists
import os
os.makedirs(shap_plot_dir, exist_ok=True)

# Create bar graphs for SHAP summary plots
for model_name, model in models.items():
    model.fit(X_train, y_train)

    # Use SHAP to calculate feature importance with KernelExplainer
    explainer = shap.KernelExplainer(model.predict, X_train)
    shap_values = explainer.shap_values(X_test, check_additivity=False)  # Disable additivity check

    # Plot and save the SHAP summary plot as a bar graph
    plt.figure(figsize=(10, 6))
    shap.summary_plot(shap_values, X_test, plot_type='bar', show=False)
    plt.title(f'SHAP Summary Bar Plot for {model_name}')
    plt.xticks(rotation=45)
    plt.tight_layout()

    # Save the SHAP summary bar graph as a JPG image
    plt.savefig(os.path.join(shap_plot_dir, f'mems_shap_summary_bar_{model_name}.jpg'))
    plt.close()
